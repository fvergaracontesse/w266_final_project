{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 6507510781861795661\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 8488640416736417990\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 9238032095547347555\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 11329991476\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 16833516007832060025\n",
      "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from time import time\n",
    "import io\n",
    "import re\n",
    "from csv import reader\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.python.keras.layers import Lambda\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.backend import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.layers import Dense, TimeDistributed\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from modules.bertLayer import BertLayer\n",
    "\n",
    "local_bert_path =   'bert' # change as needed\n",
    "data_path = 'data/train_products.csv'  # path to ner_dataset.csv file , from\n",
    "\n",
    "now = datetime.now() # current date and time\n",
    "\n",
    "# make sure that the paths are accessible within the notebook\n",
    "sys.path.insert(0,local_bert_path)\n",
    "sys.path.insert(0,data_path)\n",
    "\n",
    "import optimization\n",
    "import run_classifier\n",
    "import tokenization\n",
    "import run_classifier_with_tfhub\n",
    "\n",
    "# Tensorflow hub path to BERT module of choice\n",
    "bert_url = \"https://tfhub.dev/google/bert_multi_cased_L-12_H-768_A-12/1\"\n",
    "\n",
    "# Define maximal length of input 'sentences' (post tokenization).\n",
    "max_length = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0801 03:38:37.795906 139935840859968 deprecation_wrapper.py:119] From bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def create_tokenizer_from_hub_module():\n",
    "    \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "    with tf.Graph().as_default():\n",
    "        bert_module = hub.Module(bert_url)\n",
    "        tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "        with tf.Session() as sess:\n",
    "            vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
    "                                            tokenization_info[\"do_lower_case\"]])\n",
    "      \n",
    "    return tokenization.FullTokenizer(\n",
    "      vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "tokenizer = create_tokenizer_from_hub_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['za',\n",
       " '##pati',\n",
       " '##lla',\n",
       " 'and',\n",
       " '##1',\n",
       " 'ta',\n",
       " '##ctic',\n",
       " 'b치',\n",
       " '##sque',\n",
       " '##t',\n",
       " '##bol',\n",
       " 'hombre']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize('zapatilla and1 tactic b치squetbol hombre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10339,\n",
       " 33399,\n",
       " 11083,\n",
       " 10111,\n",
       " 10759,\n",
       " 11057,\n",
       " 35672,\n",
       " 74686,\n",
       " 37285,\n",
       " 10123,\n",
       " 22729,\n",
       " 24151]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids([\n",
    "    'za',\n",
    " '##pati',\n",
    " '##lla',\n",
    " 'and',\n",
    " '##1',\n",
    " 'ta',\n",
    " '##ctic',\n",
    " 'b치',\n",
    " '##sque',\n",
    " '##t',\n",
    " '##bol',\n",
    " 'hombre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['##ctic']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens([35672])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addWord(word, ner):\n",
    "    \"\"\"\n",
    "    Convert a word into a word token and add supplied NER and POS labels. Note that the word can be\n",
    "    tokenized to two or more tokens. Correspondingly, we add - for now - custom 'X' tokens to the labels in order to\n",
    "    maintain the 1:1 mappings between word tokens and labels.\n",
    "\n",
    "    arguments: word, pos label, ner label\n",
    "    \"\"\"\n",
    "\n",
    "    # the dataset contains various '\"\"\"' combinations which we choose to truncate to '\"', etc.\n",
    "    if word == '\"\"\"\"':\n",
    "        word = '\"'\n",
    "    elif word == '``':\n",
    "        word = '`'\n",
    "\n",
    "    tokens = tokenizer.tokenize(word)\n",
    "    tokenLength = len(tokens)      # find number of tokens corresponfing to word to later add 'X' tokens to labels\n",
    "\n",
    "    addDict = dict()\n",
    "\n",
    "    addDict['wordToken'] = tokens\n",
    "    #addDict['posToken'] = [pos] + ['posX'] * (tokenLength - 1)\n",
    "    addDict['nerToken'] = [ner] + ['nerX'] * (tokenLength - 1)\n",
    "    addDict['tokenLength'] = tokenLength\n",
    "\n",
    "\n",
    "    return addDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists for sentences, tokens, labels, etc.\n",
    "sentenceList = []\n",
    "sentenceTokenList = []\n",
    "posTokenList = []\n",
    "nerTokenList = []\n",
    "sentLengthList = []\n",
    "\n",
    "# lists for BERT input\n",
    "bertSentenceIDs = []\n",
    "bertMasks = []\n",
    "bertSequenceIDs = []\n",
    "\n",
    "sentence = ''\n",
    "\n",
    "# always start with [CLS] tokens\n",
    "sentenceTokens = ['[CLS]']\n",
    "posTokens = ['[posCLS]']\n",
    "nerTokens = ['[nerCLS]']\n",
    "\n",
    "with open('data/train_products.csv') as csv_file:\n",
    "    csv_reader = reader(csv_file, delimiter=',')\n",
    "    line = 0\n",
    "    for row in csv_reader:\n",
    "        words = row[0].split(\" \")\n",
    "        tags  = row[2].split(\" \")\n",
    "        tags.pop()\n",
    "        \n",
    "        sentenceLength = min(max_length -1, len(sentenceTokens))\n",
    "        sentLengthList.append(sentenceLength)\n",
    "        \n",
    "                    \n",
    "        # Create space for at least a final '[SEP]' token\n",
    "        if sentenceLength >= max_length - 1: \n",
    "            sentenceTokens = sentenceTokens[:max_length - 2]\n",
    "            posTokens = posTokens[:max_length - 2]\n",
    "            nerTokens = nerTokens[:max_length - 2]\n",
    "\n",
    "        # add a ['SEP'] token and padding\n",
    "        \n",
    "        sentenceTokens += ['[SEP]'] + ['[PAD]'] * (max_length -1 - len(sentenceTokens))\n",
    "        #print(sentenceTokens)\n",
    "        posTokens += ['[posSEP]'] + ['[posPAD]'] * (max_length - 1 - len(posTokens) )\n",
    "        nerTokens += ['[nerSEP]'] + ['[nerPAD]'] * (max_length - 1 - len(nerTokens) )\n",
    "            \n",
    "        sentenceList.append(sentence)\n",
    "        \n",
    "        sentenceTokenList.append(sentenceTokens)\n",
    "        \n",
    "       \n",
    "\n",
    "        bertSentenceIDs.append(tokenizer.convert_tokens_to_ids(sentenceTokens))\n",
    "        bertMasks.append([1] * (sentenceLength + 1) + [0] * (max_length -1 - sentenceLength ))\n",
    "        bertSequenceIDs.append([0] * (max_length))\n",
    "                             \n",
    "        posTokenList.append(posTokens)\n",
    "        nerTokenList.append(nerTokens)\n",
    "        \n",
    "        sentence = ''\n",
    "        sentenceTokens = ['[CLS]']\n",
    "        nerTokens = ['[nerCLS]']\n",
    "        \n",
    "        sentence += ' ' + words[0]\n",
    "        i = 0\n",
    "        for word in words:\n",
    "            #print(word)\n",
    "            ner = tags[i]\n",
    "            if i==0:\n",
    "                sentence += ' ' + word\n",
    "            addDict = addWord(word, ner)\n",
    "            #print(addDict)\n",
    "            sentenceTokens += addDict['wordToken']\n",
    "            nerTokens += addDict['nerToken']\n",
    "            i = i + 1\n",
    "        line = line + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentLengthList = sentLengthList\n",
    "sentenceTokenList = sentenceTokenList[2:]\n",
    "bertSentenceIDs = bertSentenceIDs[2:]\n",
    "bertMasks = bertMasks[2:]\n",
    "bertSequenceIDs = bertSequenceIDs[2:]\n",
    "nerTokenList = nerTokenList[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'mas', '##cara', 'blue', 'jur', '##ass', '##ic', 'world', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
     ]
    }
   ],
   "source": [
    "print(sentenceTokenList[2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[nerCLS]', 'O', 'nerX', 'O', 'B-B', 'nerX', 'nerX', 'I-B', '[nerSEP]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]']\n"
     ]
    }
   ],
   "source": [
    "print(nerTokenList[2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(bertMasks[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(bertSequenceIDs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.000e+00, 0.000e+00, 0.000e+00, 1.600e+01, 3.180e+02, 1.292e+03,\n",
       "        2.922e+03, 4.698e+03, 5.884e+03, 6.424e+03, 6.108e+03, 6.655e+03,\n",
       "        5.755e+03, 5.032e+03, 3.927e+03, 3.269e+03, 2.519e+03, 2.010e+03,\n",
       "        1.492e+03, 1.081e+03, 7.400e+02, 5.620e+02, 4.040e+02, 3.080e+02,\n",
       "        1.940e+02, 1.270e+02, 8.600e+01, 3.600e+02]),\n",
       " array([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
       "        14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26.,\n",
       "        27., 28., 29.]),\n",
       " <a list of 28 Patch objects>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentenceLengths= [l for l in sentLengthList]\n",
    "\n",
    "plt.hist(np.array(sentenceLengths), bins=(max_length-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "numSentences = len(bertSentenceIDs)\n",
    "\n",
    "nerClasses = pd.DataFrame(np.array(nerTokenList).reshape(-1))\n",
    "nerClasses.columns = ['tag']\n",
    "nerClasses.tag = pd.Categorical(nerClasses.tag)\n",
    "nerClasses['cat'] = nerClasses.tag.cat.codes\n",
    "nerClasses['sym'] = nerClasses.tag.cat.codes\n",
    "nerLabels = np.array(nerClasses.cat).reshape(numSentences, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f43d1029898>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nerClasses[['cat']].hist(bins=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>cat</th>\n",
       "      <th>occurences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-B</td>\n",
       "      <td>0</td>\n",
       "      <td>62585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I-B</td>\n",
       "      <td>1</td>\n",
       "      <td>15355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O</td>\n",
       "      <td>2</td>\n",
       "      <td>323444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[nerCLS]</td>\n",
       "      <td>3</td>\n",
       "      <td>62182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[nerPAD]</td>\n",
       "      <td>4</td>\n",
       "      <td>1021007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[nerSEP]</td>\n",
       "      <td>5</td>\n",
       "      <td>62182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nerX</td>\n",
       "      <td>6</td>\n",
       "      <td>318705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        tag  cat  occurences\n",
       "0       B-B    0       62585\n",
       "1       I-B    1       15355\n",
       "2         O    2      323444\n",
       "3  [nerCLS]    3       62182\n",
       "4  [nerPAD]    4     1021007\n",
       "5  [nerSEP]    5       62182\n",
       "6      nerX    6      318705"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nerDistribution = (nerClasses.groupby(['tag', 'cat']).agg({'sym':'count'}).reset_index()\n",
    "                   .rename(columns={'sym':'occurences'}))\n",
    "\n",
    "numNerClasses = nerDistribution.tag.nunique()\n",
    "\n",
    "nerDistribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "O_occurences = nerDistribution.loc[nerDistribution.tag == 'O','occurences']\n",
    "All_occurences = nerDistribution[nerDistribution.cat < 3]['occurences'].sum()\n",
    "\n",
    "O_occurences/All_occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_inputs = np.array([bertSentenceIDs, bertMasks, bertSequenceIDs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "numSentences = len(bert_inputs[0])\n",
    "np.random.seed(0)\n",
    "training_examples = np.random.binomial(1, 0.7, numSentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSentence_ids = []\n",
    "trainMasks = []\n",
    "trainSequence_ids = []\n",
    "\n",
    "testSentence_ids = []\n",
    "testMasks = []\n",
    "testSequence_ids = []\n",
    "\n",
    "nerLabels_train =[]\n",
    "nerLabels_test = []\n",
    "\n",
    "\n",
    "for example in range(numSentences):\n",
    "    if training_examples[example] == 1:\n",
    "        trainSentence_ids.append(bert_inputs[0][example])\n",
    "        trainMasks.append(bert_inputs[1][example])\n",
    "        trainSequence_ids.append(bert_inputs[2][example])\n",
    "        nerLabels_train.append(nerLabels[example])\n",
    "    else:\n",
    "        testSentence_ids.append(bert_inputs[0][example])\n",
    "        testMasks.append(bert_inputs[1][example])\n",
    "        testSequence_ids.append(bert_inputs[2][example])\n",
    "        nerLabels_test.append(nerLabels[example])\n",
    "        \n",
    "X_train = np.array([trainSentence_ids,trainMasks,trainSequence_ids])\n",
    "X_test = np.array([testSentence_ids,testMasks,testSequence_ids])\n",
    "\n",
    "nerLabels_train = np.array(nerLabels_train)\n",
    "nerLabels_test = np.array(nerLabels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  101, 10339, 33399, 11083, 10111, 10759, 11057, 35672, 74686,\n",
       "       37285, 10123, 22729, 24151,   102,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 6, 6, 0, 6, 2, 6, 2, 6, 6, 6, 2, 5, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4], dtype=int8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nerLabels_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'za', '##pati', '##lla', 'and', '##1', 'ta', '##ctic', 'b치', '##sque', '##t', '##bol', 'hombre', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
     ]
    }
   ],
   "source": [
    "print(sentenceTokenList[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 1, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_examples[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a parameter pair k_start, k_end to look at slices. This helps with quick tests.\n",
    "\n",
    "k_start = 0\n",
    "k_end = -1\n",
    "\n",
    "if k_end == -1:\n",
    "    k_end_train = X_train[0].shape[0]\n",
    "    k_end_test = X_test[0].shape[0]\n",
    "else:\n",
    "    k_end_train = k_end_test = k_end\n",
    "    \n",
    "\n",
    "\n",
    "bert_inputs_train_k = [X_train[0][k_start:k_end_train], X_train[1][k_start:k_end_train], \n",
    "                       X_train[2][k_start:k_end_train]]\n",
    "bert_inputs_test_k = [X_test[0][k_start:k_end_test], X_test[1][k_start:k_end_test], \n",
    "                      X_test[2][k_start:k_end_test]]\n",
    "\n",
    "\n",
    "labels_train_k = nerLabels_train[k_start:k_end_train]\n",
    "labels_test_k = nerLabels_test[k_start:k_end_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    calculate loss function explicitly, filtering out 'extra inserted labels'\n",
    "    \n",
    "    y_true: Shape: (batch x (max_length + 1) )\n",
    "    y_pred: predictions. Shape: (batch x x (max_length + 1) x num_distinct_ner_tokens ) \n",
    "    \n",
    "    returns:  cost\n",
    "    \"\"\"\n",
    "\n",
    "    #get labels and predictions\n",
    "    \n",
    "    y_label = tf.reshape(tf.layers.Flatten()(tf.cast(y_true, tf.int32)),[-1])\n",
    "    \n",
    "    mask = (y_label < 3)   # This mask is used to remove all tokens that do not correspond to the original base text.\n",
    "\n",
    "    y_label_masked = tf.boolean_mask(y_label, mask)  # mask the labels\n",
    "    \n",
    "    y_flat_pred = tf.reshape(tf.layers.Flatten()(tf.cast(y_pred, tf.float32)),[-1, numNerClasses])\n",
    "    \n",
    "    y_flat_pred_masked = tf.boolean_mask(y_flat_pred, mask) # mask the predictions\n",
    "    \n",
    "    return tf.reduce_mean(sparse_categorical_crossentropy(y_label_masked, y_flat_pred_masked,from_logits=False ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_acc_orig_tokens(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    calculate loss dfunction filtering out also the newly inserted labels\n",
    "    \n",
    "    y_true: Shape: (batch x (max_length) )\n",
    "    y_pred: predictions. Shape: (batch x x (max_length + 1) x num_distinct_ner_tokens ) \n",
    "    \n",
    "    returns: accuracy\n",
    "    \"\"\"\n",
    "\n",
    "    #get labels and predictions\n",
    "    \n",
    "    y_label = tf.reshape(tf.layers.Flatten()(tf.cast(y_true, tf.int64)),[-1])\n",
    "    \n",
    "    mask = (y_label < 3)\n",
    "    y_label_masked = tf.boolean_mask(y_label, mask)\n",
    "    \n",
    "    y_predicted = tf.math.argmax(input = tf.reshape(tf.layers.Flatten()(tf.cast(y_pred, tf.float64)),\\\n",
    "                                                    [-1, numNerClasses]), axis=1)\n",
    "    \n",
    "    y_predicted_masked = tf.boolean_mask(y_predicted, mask)\n",
    "\n",
    "    return tf.reduce_mean(tf.cast(tf.equal(y_predicted_masked,y_label_masked) , dtype=tf.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_acc_orig_non_other_tokens(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    calculate loss dfunction explicitly filtering out also the 'Other'- labels\n",
    "    \n",
    "    y_true: Shape: (batch x (max_length) )\n",
    "    y_pred: predictions. Shape: (batch x x (max_length + 1) x num_distinct_ner_tokens ) \n",
    "    \n",
    "    returns: accuracy\n",
    "    \"\"\"\n",
    "\n",
    "    #get labels and predictions\n",
    "    \n",
    "    y_label = tf.reshape(tf.layers.Flatten()(tf.cast(y_true, tf.int64)),[-1])\n",
    "    \n",
    "    mask = (y_label < 2)\n",
    "    y_label_masked = tf.boolean_mask(y_label, mask)\n",
    "    \n",
    "    y_predicted = tf.math.argmax(input = tf.reshape(tf.layers.Flatten()(tf.cast(y_pred, tf.float64)),\\\n",
    "                                                    [-1, numNerClasses]), axis=1)\n",
    "    \n",
    "    y_predicted_masked = tf.boolean_mask(y_predicted, mask)\n",
    "\n",
    "    return tf.reduce_mean(tf.cast(tf.equal(y_predicted_masked,y_label_masked) , dtype=tf.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_customized = tf.keras.optimizers.Adam(lr=0.001, beta_1=0.91, beta_2=0.999, epsilon=None, decay=0.1, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Create BERT layer, following https://towardsdatascience.com/bert-in-keras-with-tensorflow-hub-76bcbc9417b\n",
    "    init:  initialize layer. Specify various parameters regarding output types and dimensions. Very important is\n",
    "           to set the number of trainable layers.\n",
    "    build: build the layer based on parameters\n",
    "    call:  call the BERT layer within a model\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        n_fine_tune_layers=10,\n",
    "        pooling=\"sequence\",\n",
    "        bert_url=\"https://tfhub.dev/google/bert_multi_cased_L-12_H-768_A-12/1\",\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.n_fine_tune_layers = n_fine_tune_layers\n",
    "        self.trainable = True\n",
    "        self.output_size = 768\n",
    "        self.pooling = pooling\n",
    "        self.bert_url = bert_url\n",
    "\n",
    "        super(BertLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.bert = hub.Module(\n",
    "            self.bert_url, trainable=self.trainable, name=f\"{self.name}_module\"\n",
    "        )\n",
    "\n",
    "        # Remove unused layers\n",
    "        trainable_vars = self.bert.variables\n",
    "        trainable_vars = [\n",
    "                var\n",
    "                for var in trainable_vars\n",
    "                if not \"/cls/\" in var.name and not \"/pooler/\" in var.name\n",
    "            ]\n",
    "        trainable_layers = []\n",
    "\n",
    "\n",
    "        # Select how many layers to fine tune\n",
    "        for i in range(self.n_fine_tune_layers):\n",
    "            trainable_layers.append(f\"encoder/layer_{str(11 - i)}\")\n",
    "\n",
    "        # Update trainable vars to contain only the specified layers\n",
    "        trainable_vars = [\n",
    "            var\n",
    "            for var in trainable_vars\n",
    "            if any([l in var.name for l in trainable_layers])\n",
    "        ]\n",
    "\n",
    "        # Add to trainable weights\n",
    "        for var in trainable_vars:\n",
    "            self._trainable_weights.append(var)\n",
    "\n",
    "        for var in self.bert.variables:\n",
    "            if var not in self._trainable_weights:\n",
    "                self._non_trainable_weights.append(var)\n",
    "\n",
    "        super(BertLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = [K.cast(x, dtype=\"int32\") for x in inputs]\n",
    "        input_ids, input_mask, segment_ids = inputs\n",
    "        bert_inputs = dict(\n",
    "            input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids\n",
    "        )\n",
    "        result = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n",
    "                \"sequence_output\"\n",
    "            ]\n",
    "\n",
    "        mul_mask = lambda x, m: x * tf.expand_dims(m, axis=-1)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variable_summaries(var):\n",
    "    \"\"\"Attach a lot of summaries to a Tensor (for TensorBoard visualization).\"\"\"\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean', mean)\n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "        tf.summary.scalar('stddev', stddev)\n",
    "        tf.summary.scalar('max', tf.reduce_max(var))\n",
    "        tf.summary.scalar('min', tf.reduce_min(var))\n",
    "        tf.summary.histogram('histogram', var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_model(max_input_length, train_layers, optimizer):\n",
    "    \"\"\"\n",
    "    Implementation of NER model\n",
    "    \n",
    "    variables:\n",
    "        max_input_length: number of tokens (max_length + 1)\n",
    "        train_layers: number of layers to be retrained\n",
    "        optimizer: optimizer to be used\n",
    "    \n",
    "    returns: model\n",
    "    \"\"\"\n",
    "    \n",
    "    in_id = tf.keras.layers.Input(shape=(max_length,), name=\"input_ids\")\n",
    "    in_mask = tf.keras.layers.Input(shape=(max_length,), name=\"input_masks\")\n",
    "    in_segment = tf.keras.layers.Input(shape=(max_length,), name=\"segment_ids\")\n",
    "    \n",
    "    \n",
    "    bert_inputs = [in_id, in_mask, in_segment]\n",
    "    \n",
    "    bert_sequence = BertLayer(n_fine_tune_layers=train_layers)(bert_inputs)\n",
    "    \n",
    "    print(bert_sequence)\n",
    "    \n",
    "    dense = tf.keras.layers.Dense(256, activation='relu', name='dense')(bert_sequence)\n",
    "    \n",
    "    dense = tf.keras.layers.Dropout(rate=0.1)(dense)\n",
    "    \n",
    "    pred = tf.keras.layers.Dense(7, activation='softmax', name='ner')(dense)\n",
    "     \n",
    "    print('pred: ', pred)\n",
    "    \n",
    "    ## Prepare for multipe loss functions, although not used here\n",
    "    \n",
    "    losses = {\n",
    "        \"ner\": custom_loss,\n",
    "        }\n",
    "    lossWeights = {\"ner\": 1.0\n",
    "                  }\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=bert_inputs, outputs=pred)\n",
    "\n",
    "    model.compile(loss=losses, optimizer=optimizer, metrics=[custom_acc_orig_tokens, \n",
    "                                                          custom_acc_orig_non_other_tokens])\n",
    "    \n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def initialize_vars(sess):\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.tables_initializer())\n",
    "    K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Start session\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "model = ner_model(max_length + 1, train_layers=4, optimizer = adam_customized)\n",
    "\n",
    "# Instantiate variables\n",
    "initialize_vars(sess)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
    "\n",
    "model.fit(\n",
    "    bert_inputs_train_k, \n",
    "    {\"ner\": labels_train_k },\n",
    "    validation_data=(bert_inputs_test_k, {\"ner\": labels_test_k }),\n",
    "    epochs=3,\n",
    "    batch_size=256#,\n",
    "    #callbacks=[tensorboard]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_inputs_infer = [X_test[0], X_test[1], X_test[2]]\n",
    "\n",
    "result = model.predict(\n",
    "    bert_inputs_infer, \n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "numTrainSentences = 3370\n",
    "\n",
    "bert_inputs_train_tiny = [bert_inputs_train_k[0][:numTrainSentences,:], \\\n",
    "                          bert_inputs_train_k[1][:numTrainSentences,:], \\\n",
    "                          bert_inputs_train_k[2][:numTrainSentences,:]]\n",
    "\n",
    "labels_train_tiny = labels_train_k[:numTrainSentences,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0801 03:58:26.205641 139935840859968 deprecation.py:506] From /home/felipe/.local/share/virtualenvs/w266_final_project-K7oLnwuw/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"bert_layer/bert_layer_module_apply_tokens/bert/encoder/Reshape_13:0\", shape=(?, ?, 768), dtype=float32)\n",
      "pred:  Tensor(\"ner/truediv:0\", shape=(?, ?, 7), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0801 03:58:26.555308 139935840859968 deprecation.py:323] From /home/felipe/.local/share/virtualenvs/w266_final_project-K7oLnwuw/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_layer (BertLayer)          (None, None, 768)    178565115   input_ids[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 256)    196864      bert_layer[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, None, 256)    0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "ner (Dense)                     (None, None, 7)      1799        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 178,763,778\n",
      "Trainable params: 198,663\n",
      "Non-trainable params: 178,565,115\n",
      "__________________________________________________________________________________________________\n",
      "Train on 3370 samples, validate on 18556 samples\n",
      "Epoch 1/8\n",
      "3370/3370 [==============================] - 94s 28ms/sample - loss: 0.3985 - custom_acc_orig_tokens: 0.8526 - custom_acc_orig_non_other_tokens: 0.4150 - val_loss: 0.2819 - val_custom_acc_orig_tokens: 0.8976 - val_custom_acc_orig_non_other_tokens: 0.6473\n",
      "Epoch 2/8\n",
      "3370/3370 [==============================] - 92s 27ms/sample - loss: 0.2324 - custom_acc_orig_tokens: 0.9182 - custom_acc_orig_non_other_tokens: 0.6871 - val_loss: 0.2246 - val_custom_acc_orig_tokens: 0.9189 - val_custom_acc_orig_non_other_tokens: 0.7023\n",
      "Epoch 3/8\n",
      "3370/3370 [==============================] - 92s 27ms/sample - loss: 0.1732 - custom_acc_orig_tokens: 0.9391 - custom_acc_orig_non_other_tokens: 0.7701 - val_loss: 0.2016 - val_custom_acc_orig_tokens: 0.9274 - val_custom_acc_orig_non_other_tokens: 0.6820\n",
      "Epoch 4/8\n",
      "3370/3370 [==============================] - 92s 27ms/sample - loss: 0.1282 - custom_acc_orig_tokens: 0.9580 - custom_acc_orig_non_other_tokens: 0.8411 - val_loss: 0.1731 - val_custom_acc_orig_tokens: 0.9383 - val_custom_acc_orig_non_other_tokens: 0.8250\n",
      "Epoch 5/8\n",
      "3370/3370 [==============================] - 93s 27ms/sample - loss: 0.0959 - custom_acc_orig_tokens: 0.9689 - custom_acc_orig_non_other_tokens: 0.8856 - val_loss: 0.1600 - val_custom_acc_orig_tokens: 0.9435 - val_custom_acc_orig_non_other_tokens: 0.8005\n",
      "Epoch 6/8\n",
      "3370/3370 [==============================] - 92s 27ms/sample - loss: 0.0744 - custom_acc_orig_tokens: 0.9783 - custom_acc_orig_non_other_tokens: 0.9207 - val_loss: 0.1580 - val_custom_acc_orig_tokens: 0.9456 - val_custom_acc_orig_non_other_tokens: 0.8002\n",
      "Epoch 7/8\n",
      "3370/3370 [==============================] - 93s 27ms/sample - loss: 0.0551 - custom_acc_orig_tokens: 0.9851 - custom_acc_orig_non_other_tokens: 0.9425 - val_loss: 0.1516 - val_custom_acc_orig_tokens: 0.9493 - val_custom_acc_orig_non_other_tokens: 0.8089\n",
      "Epoch 8/8\n",
      "3370/3370 [==============================] - 93s 27ms/sample - loss: 0.0415 - custom_acc_orig_tokens: 0.9906 - custom_acc_orig_non_other_tokens: 0.9642 - val_loss: 0.1508 - val_custom_acc_orig_tokens: 0.9512 - val_custom_acc_orig_non_other_tokens: 0.8175\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f43c5231ba8>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "model = ner_model(max_length + 1,train_layers=0,optimizer='adam')\n",
    "\n",
    "# Instantiate variables\n",
    "initialize_vars(sess)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
    "\n",
    "model.fit(\n",
    "    bert_inputs_train_tiny, \n",
    "    {\"ner\": labels_train_tiny },\n",
    "    validation_data=(bert_inputs_test_k, {\"ner\": labels_test_k}),\n",
    "    epochs=8,\n",
    "    batch_size=32#,\n",
    "    #callbacks=[tensorboard]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  101, 12678, 67299, ...,     0,     0,     0],\n",
       "       [  101, 88406, 19403, ...,     0,     0,     0],\n",
       "       [  101, 21783, 10123, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [  101, 75156, 48590, ...,     0,     0,     0],\n",
       "       [  101, 21744, 17057, ...,     0,     0,     0],\n",
       "       [  101, 10628, 20602, ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_inputs_infer = [X_test[0], X_test[1], X_test[2]]\n",
    "\n",
    "result = model.predict(\n",
    "    bert_inputs_infer, \n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18556, 30, 7)\n"
     ]
    }
   ],
   "source": [
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 2 2 2 2 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 0 0 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(result, axis=2)[1500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 2 6 2 2 2 2 6 0 6 6 5 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n"
     ]
    }
   ],
   "source": [
    "print(nerLabels_test[1500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'lab',\n",
       " '##ial',\n",
       " 'color',\n",
       " 'sens',\n",
       " 'bold',\n",
       " 'black',\n",
       " '##est',\n",
       " 'may',\n",
       " '##belli',\n",
       " '##ne',\n",
       " '[SEP]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(X_test[0][1500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'juego',\n",
       " 'de',\n",
       " 'come',\n",
       " '##dor',\n",
       " 'new',\n",
       " 'ter',\n",
       " '##nara',\n",
       " '8',\n",
       " 'sil',\n",
       " '##las',\n",
       " 'styl',\n",
       " '##o',\n",
       " '[SEP]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentenceTokenList[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   101,  11639,  83762,  10151,  50390,  11117,  10196,  89478,\n",
       "       103450,  10457,  10929,  10884,  10686,  24033,    102,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_flat = [pred for preds in np.argmax(result, axis=2) for pred in preds]\n",
    "labels_flat = [label for labels in nerLabels_test for label in labels]\n",
    "\n",
    "clean_preds = []\n",
    "clean_labels = []\n",
    "\n",
    "for pred, label in zip(predictions_flat, labels_flat):\n",
    "    if label < 3:\n",
    "        clean_preds.append(pred)\n",
    "        clean_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = tf.math.confusion_matrix(\n",
    "    clean_labels,\n",
    "    clean_preds,\n",
    "    num_classes=None,\n",
    "    dtype=tf.dtypes.int32,\n",
    "    name=None,\n",
    "    weights=None\n",
    ").eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15224   156  3299]\n",
      " [  117  3803   677]\n",
      " [ 1265   298 94772]]\n"
     ]
    }
   ],
   "source": [
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f43bfc27400>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(cm[:-1,:-1], cmap='Reds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "w266-env",
   "language": "python",
   "name": "w266-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
